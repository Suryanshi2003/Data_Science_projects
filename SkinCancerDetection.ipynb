{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNkeHu2Oz3ONmk8pQHezuRJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Suryanshi2003/Data_Science_projects/blob/main/SkinCancerDetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "\n"
      ],
      "metadata": {
        "id": "wiXmTWfXS1hO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V7azz7woeSZu"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"KAGGLE_USERNAME\"]=\"suryanshi15\"\n",
        "os.environ[\"KAGGLE_KEY\"]=\"19fc2570419575e80c41e6922242ded5\"\n",
        "!kaggle datasets download nodoubttome/skin-cancer9-classesisic"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip skin-cancer9-classesisic.zip"
      ],
      "metadata": {
        "id": "r5yazckshR8s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11b04a81-39a3-475d-d80b-63842b0a4155"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  skin-cancer9-classesisic.zip\n",
            "replace Skin cancer ISIC The International Skin Imaging Collaboration/Test/actinic keratosis/ISIC_0010512.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_path=\"dataset/Train\"\n",
        "test_path=\"dataset/Test\""
      ],
      "metadata": {
        "id": "I_779C4njATT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names=os.listdir(train_path)\n",
        "class_names"
      ],
      "metadata": {
        "id": "RzftxwWqmJqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for name in class_names:\n",
        "  path=train_path+'/'+ name\n",
        "  n_images=len(os.listdir(path))\n",
        "  print(name,' : ', n_images)"
      ],
      "metadata": {
        "id": "pKdMs0CqPYwG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for name in class_names:\n",
        "  path=test_path+'/'+ name\n",
        "  n_images=len(os.listdir(path))\n",
        "  print(name,' : ', n_images)"
      ],
      "metadata": {
        "id": "4q1MYh4xRa1A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_img=\"dataset/Train/dermatofibroma/ISIC_0025314.jpg\""
      ],
      "metadata": {
        "id": "jHylUVEKRtRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img=cv2.imread(random_img)\n"
      ],
      "metadata": {
        "id": "MVQF3U7kSw4n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img.shape"
      ],
      "metadata": {
        "id": "2bJZpSl8TKtk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(img)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cVghrXFXTMw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(path):\n",
        "  images_list=[]\n",
        "  labels_list=[]\n",
        "  for i in range(len(class_names)):\n",
        "    dir_path=path+ \"/\" +class_names[i]\n",
        "    images= os.listdir(dir_path)\n",
        "    for j in tqdm(range(len(images))):\n",
        "      img_path=dir_path + \"/\"+ images[j]\n",
        "      img=cv2.imread(img_path)\n",
        "      img=cv2.resize(img,(224,224))\n",
        "      images_list.append(img/255.0)\n",
        "      labels_list.append(i)\n",
        "  images_list=np.asarray(images_list)\n",
        "  labels_list=np.asarray(labels_list)\n",
        "  return images_list,labels_list"
      ],
      "metadata": {
        "id": "3xeY4v6yTRfW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images,train_labels= load_data(train_path)"
      ],
      "metadata": {
        "id": "S32l3WhqXcI6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images.shape"
      ],
      "metadata": {
        "id": "PUG56h9AX0GU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_images,test_labels = load_data(test_path)"
      ],
      "metadata": {
        "id": "TG3tc8pvYlrA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "plt.imshow(train_images[564])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_d_s3IBtZHT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Data preprocessing\n",
        "train_images[0][0][0]"
      ],
      "metadata": {
        "id": "emGR8h04ZSaB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images[0][0][0]"
      ],
      "metadata": {
        "id": "DOp-CZVBeZQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#to train data from tensorflow ,first convert to tensor object not array\n",
        "BUFFER_SIZE=500\n",
        "BATCH_SIZE=32"
      ],
      "metadata": {
        "id": "AXaIJSqHefdA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D,MaxPool2D,Dense,Flatten\n",
        "from tensorflow.keras.layers import LeakyReLU,Dropout,BatchNormalization\n",
        "from tensorflow.keras.models import Model"
      ],
      "metadata": {
        "id": "fAK3kg3RexUg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_df=tf.data.Dataset.from_tensor_slices((train_images,train_labels)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "test_df=tf.data.Dataset.from_tensor_slices((test_images,test_labels)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
      ],
      "metadata": {
        "id": "sM5p4JVXfd27"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df"
      ],
      "metadata": {
        "id": "SVzjLSTZgS1B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#This is second type of model building in tensorflow"
      ],
      "metadata": {
        "id": "lxkm6U4QmmkU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#first we inherit model class\n",
        "class MyModel(Model):\n",
        "  #_init_-constructor\n",
        "  def __init__(self):\n",
        "    #calling parent class constructor\n",
        "    super().__init__()\n",
        "    #first convolutional layer\n",
        "    #32 is no.of filters\n",
        "    #3 is kernel size\n",
        "    self.conv_1_1=Conv2D(32,3,activation='relu',input_shape=(299,299,3))\n",
        "    self.conv_1_2=Conv2D(32,3,activation='relu',input_shape=(299,299,3))\n",
        "    #maxpool layer\n",
        "    self.pool_1= MaxPool2D(pool_size=(2,2))\n",
        "    self.conv_2_1=Conv2D(32,3,activation='relu')\n",
        "    self.conv_2_2=Conv2D(32,3,activation='relu')\n",
        "    #maxpool layer\n",
        "    self.pool_2= MaxPool2D(pool_size=(2,2))\n",
        "    self.conv_3_1=Conv2D(32,3,activation='relu')\n",
        "    self.conv_3_2=Conv2D(32,3,activation='relu')\n",
        "    #maxpool layer\n",
        "    self.pool_3= MaxPool2D(pool_size=(2,2))\n",
        "    #Apply flatten layer\n",
        "    self.flatten=Flatten()\n",
        "    #hidden layer\n",
        "    self.hidden_1=Dense(512)\n",
        "    self.activation=LeakyRelu()\n",
        "    self.dropout_1=Dropout(0.3)\n",
        "    self.batch_1=BatchNormalization()\n",
        "    self.hidden_2=Dense(512)\n",
        "    self.dropout_2=Dropout(0.3)\n",
        "    self.batch_2=BatchNormalization()\n",
        "    self.hidden_3=Dense(128)\n",
        "    self.dropout_3=Dropout(0.3)\n",
        "    self.batch_3=BatchNormalization()\n",
        "    self.hidden_4=Dense(64)\n",
        "    self.dropout_4=Dropout(0.3)\n",
        "    self.batch_4=BatchNormalization()\n",
        "    #Output layer\n",
        "    self.outputlayer=Dense(9,activation='softmax')\n",
        "\n",
        "  def call(self,data):\n",
        "    x=self.conv_1_1(data)\n",
        "    x=self.conv_1_2(data)\n",
        "    x=self.pool_1(x)\n",
        "    x=self.conv_2_1(x)\n",
        "    x=self.conv_2_2(x)\n",
        "    x=self.pool_2(x)\n",
        "    x=self.conv_3_1(x)\n",
        "    x=self.conv_3_2(x)\n",
        "    x=self.pool_3(x)\n",
        "    x=self.flatten(x)\n",
        "    x=self.hidden_1(x)\n",
        "    x=self.activation(x)\n",
        "    x=self.dropout_1(x)\n",
        "    x=self.batch_1(x)\n",
        "    x=self.hidden_2(x)\n",
        "    x=self.activation(x)\n",
        "    x=self.dropout_2(x)\n",
        "    x=self.batch_2(x)\n",
        "    x=self.hidden_3(x)\n",
        "    x=self.activation(x)\n",
        "    x=self.dropout_3(x)\n",
        "    x=self.batch_3(x)\n",
        "    x=self.hidden_4 (x)\n",
        "    x=self.activation(x)\n",
        "    x=self.dropout_4(x)\n",
        "    x=self.batch_4(x)\n",
        "\n",
        "    return self.outputlayer(x)"
      ],
      "metadata": {
        "id": "GAT7I0cRgf_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=MyModel()"
      ],
      "metadata": {
        "id": "WVDTFOl7kIhW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_object=tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "optimizer=tf.keras.optimizers.RMSprop()\n",
        "train_acc=tf.keras.metrics.SparseCategoricalAccuracy(name='train_acc')\n",
        "test_acc=tf.keras.metrics.SparseCategoricalAccuracy(name='test_acc')\n",
        "\n",
        "train_loss=tf.keras.metrics.Mean(name='train_loss')\n",
        "test_loss=tf.keras.metrics.Mean(name='test_loss')"
      ],
      "metadata": {
        "id": "ymqjngMElYZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Decorators- we pass function as an arguement in another function\n",
        "#here @tf.function is a decorator\n",
        "#Now it means that there is a  function in tensorflow whose name is function\n",
        "#now when model starts to train then train_step function will be passed as an arguement inside decorator\n",
        "@tf.function\n",
        "def train_step(train_images,train_labels):\n",
        "  #now once we start tensorflow graph it will initiate process of gradient descent\n",
        "  with tf.GradientTape() as tape:\n",
        "    #it will execute call that we define in our class\n",
        "    predictions=model(train_images)\n",
        "    #now we will calculate loss on our training data\n",
        "    loss=loss_object(train_labels,predictions)\n",
        "\n",
        "    #optimization\n",
        "    #it will keep track of gradients for your computers\n",
        "    grad=tape.gradient(loss,model.trainable_variables)\n",
        "    #apply optimization- it will update weights and bias\n",
        "    optimizer.apply_gradients(zip(grad,model.trainable_variables))\n",
        "\n",
        "    train_loss(loss)\n",
        "    train_acc(train_labels,predictions)"
      ],
      "metadata": {
        "id": "JFCiyhGjtwHf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def test_step(test_images,test_labels):\n",
        "  predictions=model(test_images)\n",
        "  loss=loss_object(test_labels,predictions)\n",
        "  test_loss(loss)\n",
        "  test_acc(test_labels,predictions)\n"
      ],
      "metadata": {
        "id": "eb_dUjB1zUf8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=50\n",
        "for epoch in range(epochs):\n",
        "  train_loss.reset_states()\n",
        "  train_acc.reset_states()\n",
        "  test_loss.reset_states()\n",
        "  test_acc.reset_states()\n",
        "  for images,labels in train_df:\n",
        "    train_step(images,labels)\n",
        "  for images,labels in test_df:\n",
        "    test_step(images,labels)\n",
        "\n",
        "  print(\"Epoch : {} | Train Loss : {:.3f} | Train Acc : {:.3f} | Test Loss : {} | Test Acc {}\".format(\n",
        "                                                                                              epochs,train_loss.result(),\n",
        "                                                                                              train_acc.result(),\n",
        "                                                                                              test_loss.result(),\n",
        "                                                                                              test_acc.result()))"
      ],
      "metadata": {
        "id": "X4WM95ha28cV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oXCzlsGd5uHH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}